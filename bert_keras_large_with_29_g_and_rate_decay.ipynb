{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_keras_large_with_29_g_and_rate_decay.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO1y_BmZGJcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install tensorflow==1.13.1\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FccPbmCxJNvd",
        "colab_type": "code",
        "outputId": "ba162fbf-2e7b-41dd-b3ea-bfc6ae554a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 16.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 2.3MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 3.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.7MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 3.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 4.1MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 4.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 3.5MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mVaQWBKaEkrp",
        "colab_type": "code",
        "outputId": "dc433b37-6345-4b2f-d2cd-01d1681a0660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "os.environ['TF_KERAS'] = '1'\n",
        "import sys\n",
        "import random\n",
        "#import keras\n",
        "import tensorflow as tf\n",
        "import json\n",
        "UPLOAD_TIME = '2019_05_30' #@param {type:\"string\"}\n",
        "BERT_MODEL = 'wwm_uncased_L-24_H-1024_A-16' #@param {type:\"string\"}\n",
        "download_url = 'https://storage.googleapis.com/bert_models/{}/{}.zip'.format(UPLOAD_TIME,BERT_MODEL)\n",
        "zip_path = '{}.zip'.format(BERT_MODEL)\n",
        "! test -d $BERT_MODEL || (wget $download_url && unzip $zip_path)\n",
        "BERT_PRETRAINED_DIR = os.path.realpath(BERT_MODEL)\n",
        "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py\n",
        "import tokenization  #Actually keras_bert contains tokenization part, here just for convenience"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-29 10:26:10--  https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.196.128, 2607:f8b0:4001:c02::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.196.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1248381879 (1.2G) [application/zip]\n",
            "Saving to: ‘wwm_uncased_L-24_H-1024_A-16.zip’\n",
            "\n",
            "wwm_uncased_L-24_H- 100%[===================>]   1.16G  72.4MB/s    in 13s     \n",
            "\n",
            "2019-07-29 10:26:24 (92.1 MB/s) - ‘wwm_uncased_L-24_H-1024_A-16.zip’ saved [1248381879/1248381879]\n",
            "\n",
            "Archive:  wwm_uncased_L-24_H-1024_A-16.zip\n",
            "   creating: wwm_uncased_L-24_H-1024_A-16/\n",
            "  inflating: wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt.meta  \n",
            "  inflating: wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: wwm_uncased_L-24_H-1024_A-16/vocab.txt  \n",
            "  inflating: wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt.index  \n",
            "  inflating: wwm_uncased_L-24_H-1024_A-16/bert_config.json  \n",
            "***** BERT pretrained directory: /content/wwm_uncased_L-24_H-1024_A-16 *****\n",
            "--2019-07-29 10:26:55--  https://raw.githubusercontent.com/google-research/bert/master/tokenization.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12257 (12K) [text/plain]\n",
            "Saving to: ‘tokenization.py’\n",
            "\n",
            "tokenization.py     100%[===================>]  11.97K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-29 10:27:04 (99.8 MB/s) - ‘tokenization.py’ saved [12257/12257]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUSXeWFTGCtg",
        "colab_type": "code",
        "outputId": "99052e51-53a0-4749-8550-9318716d637a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "! pip install keras-bert -q"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cra31KPlI--c",
        "colab_type": "code",
        "outputId": "04203cce-6ab1-4056-c216-6f2a0bd42329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "def loadfrommydrive():  \n",
        "  link = 'https://drive.google.com/open?id=1Uhre5CGrs7xdTAILCcseKPiJw073Czxw' # The shareable link\n",
        "  fluff, id = link.split('=')\n",
        "  print (id) # Verify that you have everything after '='\n",
        "  downloaded1 = drive.CreateFile({'id':id}) \n",
        "  downloaded1.GetContentFile('train.csv.zip')\n",
        "\n",
        "  link = 'https://drive.google.com/open?id=1neE7a2COjKXDA6LB7RFRb2lu5Ksy5frp' # The shareable link\n",
        "  fluff, id = link.split('=')\n",
        "  print (id) # Verify that you have everything after '='\n",
        "  downloaded2 = drive.CreateFile({'id':id}) \n",
        "  downloaded2 = drive.CreateFile({'id':id}) \n",
        "  downloaded2.GetContentFile('test.csv.zip')  \n",
        "  # Dataset is now stored in a Pandas Dataframe\n",
        "  # Dataset is now stored in a Pandas Dataframe\n",
        "  link = 'https://drive.google.com/open?id=1Aan7JSlxGPUEJgrO1cITMM0F2n6z_X9h' # The shareable link\n",
        "  fluff, id = link.split('=')\n",
        "  print (id) # Verify that you have everything after '='\n",
        "  downloaded1 = drive.CreateFile({'id':id}) \n",
        "  downloaded1.GetContentFile('new7_train_input_220.npy')\n",
        "\n",
        "loadfrommydrive()\n",
        "! unzip train.csv.zip\n",
        "! unzip test.csv.zip\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1Uhre5CGrs7xdTAILCcseKPiJw073Czxw\n",
            "1neE7a2COjKXDA6LB7RFRb2lu5Ksy5frp\n",
            "1Aan7JSlxGPUEJgrO1cITMM0F2n6z_X9h\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxi0O8EYEkr0",
        "colab_type": "text"
      },
      "source": [
        "## Parameters and load training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BS_-7YxPEkr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 3e-5\n",
        "weight_decay = 0.01\n",
        "nb_epochs=1\n",
        "bsz = 64\n",
        "maxlen=220\n",
        "sigma= 0.998\n",
        "## Training data\n",
        "## step parameter \n",
        "decay_steps = int(1.2*nb_epochs*1804874/bsz)\n",
        "warmup_steps = int(0.05*decay_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FvRl1yzsEkr5",
        "colab_type": "code",
        "outputId": "2061623f-099e-42b5-fc94-80761721faef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "#from keras_bert.bert import get_model\n",
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "print('begin_build')\n",
        "\n",
        "config_file = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
        "checkpoint_file = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
        "model = load_trained_model_from_checkpoint(config_file, checkpoint_file, training=True,seq_len=maxlen)\n",
        "#model.summary(line_length=120)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin_build\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueYSTtVsEkr4",
        "colab_type": "text"
      },
      "source": [
        "## Load raw model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXBC8L-nEkr-",
        "colab_type": "text"
      },
      "source": [
        "## Build classification model with adamwarmup\n",
        "\n",
        "First folk the optimizer with excluding \"bias\" and \"Norm\" parameters from weight decay:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ETq2ilnwEksD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.python import keras\n",
        "def get_multiplier(p,lr_t):\n",
        "  if 'Input' in p.name or 'Embedding' in p.name:\n",
        "    return lr_t*(sigma**23)\n",
        "  elif 'Extract' in p.name or 'real_output' in p.name or 'aux_output' in p.name:\n",
        "    return lr_t*(sigma**0)\n",
        "  else:\n",
        "    for i in range(1,25):\n",
        "      if '{}'.format(i) in p.name:\n",
        "        return lr_t*(sigma**(24-i))\n",
        "            \n",
        "class AdamWarmup(keras.optimizers.Optimizer):\n",
        "    def __init__(self, decay_steps, warmup_steps, min_lr=0.0,\n",
        "                 lr=0.001, beta_1=0.9, beta_2=0.999,\n",
        "                 epsilon=None, kernel_weight_decay=0., bias_weight_decay=0.,\n",
        "                 amsgrad=False, **kwargs):\n",
        "        super(AdamWarmup, self).__init__(**kwargs)\n",
        "        with K.name_scope(self.__class__.__name__):\n",
        "            self.decay_steps = K.variable(decay_steps, name='decay_steps')\n",
        "            self.warmup_steps = K.variable(warmup_steps, name='warmup_steps')\n",
        "            self.min_lr = K.variable(min_lr, name='min_lr')\n",
        "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
        "            self.lr = K.variable(lr, name='lr')\n",
        "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
        "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
        "            self.kernel_weight_decay = K.variable(kernel_weight_decay, name='kernel_weight_decay')\n",
        "            self.bias_weight_decay = K.variable(bias_weight_decay, name='bias_weight_decay')\n",
        "        if epsilon is None:\n",
        "            epsilon = K.epsilon()\n",
        "        self.epsilon = epsilon\n",
        "        self.initial_kernel_weight_decay = kernel_weight_decay\n",
        "        self.initial_bias_weight_decay = bias_weight_decay\n",
        "        self.amsgrad = amsgrad\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "\n",
        "        lr = K.switch(\n",
        "            t <= self.warmup_steps,\n",
        "            self.lr * (t / self.warmup_steps),\n",
        "            self.lr * (1.0 - K.minimum(t, self.decay_steps) / self.decay_steps),\n",
        "        )\n",
        "\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
        "                     (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        if self.amsgrad:\n",
        "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        else:\n",
        "            vhats = [K.zeros(1) for _ in params]\n",
        "        self.weights = [self.iterations] + ms + vs + vhats\n",
        "\n",
        "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
        "            new_lr_t = get_multiplier(p,lr_t)#lr_t#\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            if self.amsgrad:\n",
        "                vhat_t = K.maximum(vhat, v_t)\n",
        "                p_t = m_t / (K.sqrt(vhat_t) + self.epsilon)\n",
        "                self.updates.append(K.update(vhat, vhat_t))\n",
        "            else:\n",
        "                p_t = m_t / (K.sqrt(v_t) + self.epsilon)\n",
        "\n",
        "            if 'bias' not in p.name and 'Norm' not in p.name:\n",
        "                if self.initial_bias_weight_decay > 0.0:\n",
        "                    p_t += self.bias_weight_decay * p\n",
        "            else:\n",
        "                if self.initial_kernel_weight_decay > 0.0:\n",
        "                    p_t += self.kernel_weight_decay * p\n",
        "            p_t = p - new_lr_t * p_t\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            new_p = p_t\n",
        "\n",
        "            if getattr(p, 'constraint', None) is not None:\n",
        "                new_p = p.constraint(new_p)\n",
        "\n",
        "            self.updates.append(K.update(p, new_p))\n",
        "        return self.updates\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'decay_steps': float(K.get_value(self.decay_steps)),\n",
        "            'warmup_steps': float(K.get_value(self.warmup_steps)),\n",
        "            'min_lr': float(K.get_value(self.min_lr)),\n",
        "            'lr': float(K.get_value(self.lr)),\n",
        "            'beta_1': float(K.get_value(self.beta_1)),\n",
        "            'beta_2': float(K.get_value(self.beta_2)),\n",
        "            'epsilon': self.epsilon,\n",
        "            'kernel_weight_decay': float(K.get_value(self.kernel_weight_decay)),\n",
        "            'bias_weight_decay': float(K.get_value(self.bias_weight_decay)),\n",
        "            'amsgrad': self.amsgrad,\n",
        "        }\n",
        "        base_config = super(AdamWarmup, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJBRuQa0EksG",
        "colab_type": "text"
      },
      "source": [
        "As the Extract layer extracts only the first token where \"['CLS']\" used to be, we just take the layer and connect to the single neuron output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H63QLM7SlEDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#weights and custom_loss ours before\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "def loadeverything():\n",
        "  train_df = pd.read_csv('train.csv')\n",
        "  train_df = train_df.sample(frac=1.0,random_state = 42+50000)\n",
        "  AUX_COLUMNS = ['severe_toxicity','obscene','identity_attack','insult','threat','sexual_explicit']\n",
        "  identity_columns = [\n",
        "      'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
        "      'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
        "  coll = ['black','white','homosexual_gay_or_lesbian','muslim']\n",
        "\n",
        "  weights = np.ones((len(train_df),)) / 4\n",
        "  # Subgroup  identity_columns  > 0.5\n",
        "  weights += (train_df[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) / 4\n",
        "  # Background Positive, Subgroup Negative\n",
        "  weights += (( (train_df['target'].values>=0.5).astype(bool).astype(np.int) +\n",
        "     (train_df[identity_columns].fillna(0).values<0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) / 4\n",
        "  # Background Negative, Subgroup Positive\n",
        "  weights += (( (train_df['target'].values<0.5).astype(bool).astype(np.int) +\n",
        "     (train_df[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) / 4\n",
        "\n",
        "  weights += (( (train_df['target'].values>=0.5).astype(bool).astype(np.int) +\n",
        "     (train_df[coll].fillna(0).values<0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) /8\n",
        "\n",
        "  weights += (( (train_df['target'].values<0.5).astype(bool).astype(np.int) +\n",
        "     (train_df[coll].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) / 8\n",
        "\n",
        "  loss_weight = 1.0 / weights.mean()\n",
        "  weights =weights.reshape(-1,1)\n",
        "\n",
        "  y_aux = train_df[AUX_COLUMNS].values\n",
        "  ###\n",
        "  y = train_df['target'].values[:,None]\n",
        "  y = np.hstack([y,weights])\n",
        "  train_df = train_df.drop(['comment_text'], axis=1)\n",
        "  train_idx = train_df.index.values\n",
        "  print(train_idx)\n",
        "  #np.random.shuffle(train_idx[:180032*9])\n",
        "  #print(train_idx)\n",
        "  test_df = train_df.tail(180032)\n",
        "  return loss_weight,y_aux,y,train_idx,test_df\n",
        "loss_weight,y_aux,y,train_idx,test_df = loadeverything()\n",
        "\n",
        "def custom_loss(y_true, y_pred):\n",
        "  return binary_crossentropy(K.reshape(y_true[:,0],(-1,1)),y_pred) * y_true[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3dwW8V1yEksH",
        "colab_type": "code",
        "outputId": "11a27787-adce-4883-dda4-d433fb3c2d50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.python import keras\n",
        "#import keras.backend as K\n",
        "import re\n",
        "import codecs\n",
        "def createmodel():\n",
        "  adamwarm = AdamWarmup(lr=lr,decay_steps = decay_steps, warmup_steps = warmup_steps,kernel_weight_decay = weight_decay)\n",
        "  sequence_output  = model.get_layer('Extract').output\n",
        "  pool_output = keras.layers.Dense(units=1, activation='sigmoid',name='real_output')(sequence_output)\n",
        "  aux_output = keras.layers.Dense(units=6, activation='sigmoid',name='aux_output')(sequence_output)\n",
        "  model3  = keras.models.Model(inputs=model.input, outputs=[pool_output,aux_output])\n",
        "  model3.compile(loss=[custom_loss,'binary_crossentropy'],loss_weights=[loss_weight,6.],optimizer=adamwarm)\n",
        "  model3.summary()\n",
        "  return model3\n",
        "model3 = createmodel()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        (None, 220)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      (None, 220)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding [(None, 220, 1024),  31254528    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, 220, 1024)    2048        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, 220, 1024)    0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, 220, 1024)    225280      Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, 220, 1024)    0           Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, 220, 1024)    2048        Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 220, 1024)    4198400     Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 220, 1024)    0           Embedding-Norm[0][0]             \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 220, 1024)    2048        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, 220, 1024)    8393728     Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, 220, 1024)    0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, 220, 1024)    0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, 220, 1024)    2048        Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 220, 1024)    4198400     Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 220, 1024)    2048        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, 220, 1024)    8393728     Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, 220, 1024)    0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, 220, 1024)    0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, 220, 1024)    2048        Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 220, 1024)    4198400     Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-3-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 220, 1024)    2048        Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForw (None, 220, 1024)    8393728     Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout ( (None, 220, 1024)    0           Encoder-3-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add) (None, 220, 1024)    0           Encoder-3-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (Lay (None, 220, 1024)    2048        Encoder-3-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 220, 1024)    4198400     Encoder-3-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-4-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 220, 1024)    2048        Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForw (None, 220, 1024)    8393728     Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout ( (None, 220, 1024)    0           Encoder-4-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add) (None, 220, 1024)    0           Encoder-4-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (Lay (None, 220, 1024)    2048        Encoder-4-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 220, 1024)    4198400     Encoder-4-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-5-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-4-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 220, 1024)    2048        Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForw (None, 220, 1024)    8393728     Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout ( (None, 220, 1024)    0           Encoder-5-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add) (None, 220, 1024)    0           Encoder-5-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (Lay (None, 220, 1024)    2048        Encoder-5-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 220, 1024)    4198400     Encoder-5-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-6-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-5-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 220, 1024)    2048        Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForw (None, 220, 1024)    8393728     Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout ( (None, 220, 1024)    0           Encoder-6-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add) (None, 220, 1024)    0           Encoder-6-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (Lay (None, 220, 1024)    2048        Encoder-6-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 220, 1024)    4198400     Encoder-6-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-7-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-6-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 220, 1024)    2048        Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForw (None, 220, 1024)    8393728     Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout ( (None, 220, 1024)    0           Encoder-7-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add) (None, 220, 1024)    0           Encoder-7-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (Lay (None, 220, 1024)    2048        Encoder-7-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 220, 1024)    4198400     Encoder-7-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-8-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-7-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 220, 1024)    2048        Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForw (None, 220, 1024)    8393728     Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout ( (None, 220, 1024)    0           Encoder-8-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add) (None, 220, 1024)    0           Encoder-8-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (Lay (None, 220, 1024)    2048        Encoder-8-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 220, 1024)    4198400     Encoder-8-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-9-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 220, 1024)    0           Encoder-8-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 220, 1024)    2048        Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForw (None, 220, 1024)    8393728     Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout ( (None, 220, 1024)    0           Encoder-9-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add) (None, 220, 1024)    0           Encoder-9-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (Lay (None, 220, 1024)    2048        Encoder-9-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-9-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-9-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-10-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-10-MultiHeadSelfAttention\n",
            "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-10-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-10-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-10-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-11-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-11-MultiHeadSelfAttention\n",
            "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-11-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-11-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-11-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-12-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-12-MultiHeadSelfAttention\n",
            "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-12-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-13-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-12-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-13-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-13-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-13-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-12-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-13-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-13-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-13-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-13-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-13-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-13-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-13-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-13-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-13-MultiHeadSelfAttention\n",
            "                                                                 Encoder-13-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-13-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-13-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-14-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-13-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-14-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-14-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-14-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-13-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-14-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-14-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-14-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-14-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-14-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-14-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-14-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-14-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-14-MultiHeadSelfAttention\n",
            "                                                                 Encoder-14-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-14-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-14-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-15-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-14-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-15-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-15-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-15-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-14-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-15-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-15-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-15-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-15-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-15-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-15-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-15-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-15-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-15-MultiHeadSelfAttention\n",
            "                                                                 Encoder-15-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-15-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-15-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-16-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-15-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-16-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-16-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-16-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-15-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-16-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-16-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-16-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-16-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-16-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-16-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-16-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-16-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-16-MultiHeadSelfAttention\n",
            "                                                                 Encoder-16-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-16-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-16-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-17-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-16-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-17-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-17-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-17-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-16-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-17-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-17-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-17-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-17-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-17-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-17-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-17-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-17-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-17-MultiHeadSelfAttention\n",
            "                                                                 Encoder-17-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-17-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-17-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-18-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-17-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-18-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-18-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-18-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-17-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-18-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-18-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-18-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-18-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-18-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-18-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-18-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-18-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-18-MultiHeadSelfAttention\n",
            "                                                                 Encoder-18-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-18-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-18-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-19-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-18-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-19-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-19-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-19-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-18-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-19-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-19-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-19-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-19-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-19-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-19-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-19-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-19-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-19-MultiHeadSelfAttention\n",
            "                                                                 Encoder-19-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-19-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-19-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-20-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-19-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-20-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-20-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-20-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-19-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-20-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-20-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-20-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-20-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-20-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-20-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-20-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-20-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-20-MultiHeadSelfAttention\n",
            "                                                                 Encoder-20-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-20-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-20-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-21-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-20-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-21-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-21-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-21-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-20-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-21-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-21-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-21-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-21-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-21-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-21-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-21-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-21-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-21-MultiHeadSelfAttention\n",
            "                                                                 Encoder-21-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-21-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-21-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-22-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-21-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-22-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-22-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-22-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-21-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-22-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-22-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-22-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-22-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-22-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-22-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-22-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-22-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-22-MultiHeadSelfAttention\n",
            "                                                                 Encoder-22-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-22-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-22-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-23-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-22-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-23-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-23-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-23-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-22-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-23-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-23-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-23-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-23-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-23-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-23-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-23-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-23-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-23-MultiHeadSelfAttention\n",
            "                                                                 Encoder-23-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-23-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-23-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-24-MultiHeadSelfAttenti (None, 220, 1024)    4198400     Encoder-23-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-24-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-24-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-24-MultiHeadSelfAttenti (None, 220, 1024)    0           Encoder-23-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-24-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-24-MultiHeadSelfAttenti (None, 220, 1024)    2048        Encoder-24-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-24-FeedForward (FeedFor (None, 220, 1024)    8393728     Encoder-24-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-24-FeedForward-Dropout  (None, 220, 1024)    0           Encoder-24-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-24-FeedForward-Add (Add (None, 220, 1024)    0           Encoder-24-MultiHeadSelfAttention\n",
            "                                                                 Encoder-24-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-24-FeedForward-Norm (La (None, 220, 1024)    2048        Encoder-24-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Extract (Extract)               (None, 1024)         0           Encoder-24-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "real_output (Dense)             (None, 1)            1025        Extract[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "aux_output (Dense)              (None, 6)            6150        Extract[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 333,800,455\n",
            "Trainable params: 333,800,455\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjxjW9swH_z9",
        "colab_type": "code",
        "outputId": "72f74603-54ca-4222-abdd-329c0f3f7656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "# @title Initialize Variables\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from keras_bert import get_custom_objects\n",
        "\n",
        "sess = K.get_session()\n",
        "uninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\n",
        "init_op = tf.variables_initializer(\n",
        "    [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]\n",
        ")\n",
        "sess.run(init_op)\n",
        "\n",
        "\n",
        "tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "strategy = tf.contrib.tpu.TPUDistributionStrategy(\n",
        "    tf.contrib.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
        ")\n",
        "\n",
        "with tf.keras.utils.custom_object_scope(get_custom_objects()):\n",
        "    model3 = tf.contrib.tpu.keras_to_tpu_model(model3, strategy=strategy)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.30.143.210:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 1794948670499916486)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 16711173968620041571)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 18096171597325454457)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16585903583717639435)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 9160151419783854817)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 13591535421854519846)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 11770632655835126528)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 403545418941533355)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 11447168728627979891)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2012911192950830320)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 3078879979235730055)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning AdamWarmup {'decay_steps': 33841.0, 'warmup_steps': 1692.0, 'min_lr': 0.0, 'lr': 2.9999999242136255e-05, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'epsilon': 1e-07, 'kernel_weight_decay': 0.009999999776482582, 'bias_weight_decay': 0.0, 'amsgrad': False}\n",
            "INFO:tensorflow:Cloning AdamWarmup {'decay_steps': 33841.0, 'warmup_steps': 1692.0, 'min_lr': 0.0, 'lr': 2.9999999242136255e-05, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'epsilon': 1e-07, 'kernel_weight_decay': 0.009999999776482582, 'bias_weight_decay': 0.0, 'amsgrad': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT30AvgMEksW",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Data, Training, Predicting\n",
        "\n",
        "First the model need train data like [token_input,seg_input,masked input], here we set all segment input to 0 and all masked input to 1.\n",
        "\n",
        "Still I am finding a more efficient way to do token-convert-to-ids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r4jAM7diEksX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "cd18da9b-c610-4bd4-fdf5-d5c708f35f25"
      },
      "source": [
        "#print('sample used',train_df.shape[0])\n",
        "#token_input = (np.load('new7_train_input_220.npy')[train_idx])\n",
        "def runep1():\n",
        "  token_input = (np.load('new7_train_input_220.npy')[train_idx])#[:16000]\n",
        "  mask_input = np.ones((180032,maxlen))\n",
        "  token_input2 = token_input[-180032:]\n",
        "  np.save('token_input2',token_input2)\n",
        "  #mask_input = np.ones((16000,maxlen))\n",
        "  print(token_input.shape)\n",
        "  #print(seg_input.shape)\n",
        "  print(mask_input.shape)\n",
        "  print('begin training')\n",
        "  with tf.keras.utils.custom_object_scope(get_custom_objects()):\n",
        "    for i in range(9):\n",
        "    #for i in range(1):\n",
        "      seg_input = np.zeros((180032,maxlen))\n",
        "      #seg_input = np.zeros((16000,maxlen))\n",
        "      #seg_input[(token_input[(180032*i):(180032*(i+1))])!=0]=1\n",
        "      model3.fit([token_input[(180032*i):(180032*(i+1))], seg_input, mask_input],[y[(180032*i):(180032*(i+1))],\n",
        "                                                                                  y_aux[(180032*i):(180032*(i+1))]],batch_size=bsz,epochs=nb_epochs)\n",
        "      #model3.fit([token_input[(16000*i):(16000*(i+1))], seg_input, mask_input],[y[(16000*i):(16000*(i+1))],\n",
        "      #                                                                           y_aux[(16000*i):(16000*(i+1))]],batch_size=bsz,epochs=nb_epochs)\n",
        "  return model3\n",
        "model3 = runep1()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1804874, 220)\n",
            "(180032, 220)\n",
            "begin training\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(8,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(8, 220), dtype=tf.float32, name='Input-Token_10'), TensorSpec(shape=(8, 220), dtype=tf.float32, name='Input-Segment_10'), TensorSpec(shape=(8, 220), dtype=tf.float32, name='Input-Masked_10'), TensorSpec(shape=(8, 2), dtype=tf.float32, name='real_output_target_30'), TensorSpec(shape=(8, 6), dtype=tf.float32, name='aux_output_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning AdamWarmup {'decay_steps': 33841.0, 'warmup_steps': 1692.0, 'min_lr': 0.0, 'lr': 2.9999999242136255e-05, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'epsilon': 1e-07, 'kernel_weight_decay': 0.009999999776482582, 'bias_weight_decay': 0.0, 'amsgrad': False}\n",
            "INFO:tensorflow:Remapping placeholder for Input-Token\n",
            "INFO:tensorflow:Remapping placeholder for Input-Segment\n",
            "INFO:tensorflow:Remapping placeholder for Input-Masked\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:KerasCrossShard: <__main__.AdamWarmup object at 0x7f2335a9e710> []\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 191.2402777671814 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:CPU -> TPU decay_steps: 33841.0 {33841.0}\n",
            "INFO:tensorflow:CPU -> TPU warmup_steps: 1692.0 {1692.0}\n",
            "INFO:tensorflow:CPU -> TPU min_lr: 0.0 {0.0}\n",
            "INFO:tensorflow:CPU -> TPU lr: 2.9999999242136255e-05 {3e-05}\n",
            "INFO:tensorflow:CPU -> TPU beta_1: 0.8999999761581421 {0.9}\n",
            "INFO:tensorflow:CPU -> TPU beta_2: 0.9990000128746033 {0.999}\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:CPU -> TPU kernel_weight_decay: 0.009999999776482582 {0.01}\n",
            "INFO:tensorflow:CPU -> TPU bias_weight_decay: 0.0 {0.0}\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "180032/180032 [==============================] - 2145s 12ms/sample - loss: 0.8744 - real_output_loss: 0.1003 - aux_output_loss: 0.1003\n",
            "180032/180032 [==============================] - 1418s 8ms/sample - loss: 0.7102 - real_output_loss: 0.0830 - aux_output_loss: 0.0830\n",
            "180032/180032 [==============================] - 1417s 8ms/sample - loss: 0.7024 - real_output_loss: 0.0820 - aux_output_loss: 0.0820\n",
            "180032/180032 [==============================] - 1414s 8ms/sample - loss: 0.6941 - real_output_loss: 0.0812 - aux_output_loss: 0.0812\n",
            "180032/180032 [==============================] - 1418s 8ms/sample - loss: 0.6940 - real_output_loss: 0.0811 - aux_output_loss: 0.0811\n",
            "180032/180032 [==============================] - 1418s 8ms/sample - loss: 0.6944 - real_output_loss: 0.0811 - aux_output_loss: 0.0811\n",
            "180032/180032 [==============================] - 1421s 8ms/sample - loss: 0.6935 - real_output_loss: 0.0810 - aux_output_loss: 0.0810\n",
            "180032/180032 [==============================] - 1419s 8ms/sample - loss: 0.6878 - real_output_loss: 0.0804 - aux_output_loss: 0.0804\n",
            "180032/180032 [==============================] - 1421s 8ms/sample - loss: 0.6880 - real_output_loss: 0.0804 - aux_output_loss: 0.0804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TjsJ3VAPEksb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "f282fa80-8fc4-41f1-9871-77e55600f65f"
      },
      "source": [
        "#valid test data\n",
        "\n",
        "print('valid data done')\n",
        "def run_pred1():\n",
        "  #token_input = (np.load('new7_train_input_220.npy')[train_idx])\n",
        "  token_input2 = np.load('token_input2.npy')#token_input[-180032:]\n",
        "  with tf.keras.utils.custom_object_scope(get_custom_objects()):\n",
        "    seg_input = np.zeros((180032,maxlen))\n",
        "    mask_input = np.ones((180032,maxlen))\n",
        "    #seg_input[token_input2!=0]=1\n",
        "    hehe = model3.predict([token_input2, seg_input, mask_input],verbose=1,batch_size=bsz)\n",
        "  return hehe\n",
        "hehe = run_pred1()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "valid data done\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=infer (# of cores 8), [TensorSpec(shape=(8, 220), dtype=tf.float32, name='Input-Token_10'), TensorSpec(shape=(8, 220), dtype=tf.float32, name='Input-Segment_10'), TensorSpec(shape=(8, 220), dtype=tf.float32, name='Input-Masked_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning AdamWarmup {'decay_steps': 33841.0, 'warmup_steps': 1692.0, 'min_lr': 0.0, 'lr': 2.9999999242136255e-05, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'epsilon': 1e-07, 'kernel_weight_decay': 0.009999999776482582, 'bias_weight_decay': 0.0, 'amsgrad': False}\n",
            "INFO:tensorflow:Remapping placeholder for Input-Token\n",
            "INFO:tensorflow:Remapping placeholder for Input-Segment\n",
            "INFO:tensorflow:Remapping placeholder for Input-Masked\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 87.43157434463501 secs\n",
            "180032/180032 [==============================] - 502s 3ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LgNz8NZmu6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From baseline kernel\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "def calculate_overall_auc(df, model_name):\n",
        "    true_labels = df[TOXICITY_COLUMN]>0.5\n",
        "    predicted_labels = df[model_name]\n",
        "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
        "\n",
        "def power_mean(series, p):\n",
        "    total = sum(np.power(series, p))\n",
        "    return np.power(total / len(series), 1 / p)\n",
        "\n",
        "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
        "    bias_score = np.average([\n",
        "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
        "        power_mean(bias_df[BPSN_AUC], POWER),\n",
        "        power_mean(bias_df[BNSP_AUC], POWER)\n",
        "    ])\n",
        "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
        "\n",
        "\n",
        "\n",
        "SUBGROUP_AUC = 'subgroup_auc'\n",
        "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
        "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
        "\n",
        "def compute_auc(y_true, y_pred):\n",
        "    try:\n",
        "        return metrics.roc_auc_score(y_true, y_pred)\n",
        "    except ValueError:\n",
        "        return np.nan\n",
        "\n",
        "def compute_subgroup_auc(df, subgroup, label, model_name):\n",
        "    subgroup_examples = df[df[subgroup]>0.5]\n",
        "    return compute_auc((subgroup_examples[label]>0.5), subgroup_examples[model_name])\n",
        "\n",
        "def compute_bpsn_auc(df, subgroup, label, model_name):\n",
        "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
        "    subgroup_negative_examples = df[(df[subgroup]>0.5) & (df[label]<=0.5)]\n",
        "    non_subgroup_positive_examples = df[(df[subgroup]<=0.5) & (df[label]>0.5)]\n",
        "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
        "    return compute_auc(examples[label]>0.5, examples[model_name])\n",
        "\n",
        "def compute_bnsp_auc(df, subgroup, label, model_name):\n",
        "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
        "    subgroup_positive_examples = df[(df[subgroup]>0.5) & (df[label]>0.5)]\n",
        "    non_subgroup_negative_examples = df[(df[subgroup]<=0.5) & (df[label]<=0.5)]\n",
        "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
        "    return compute_auc(examples[label]>0.5, examples[model_name])\n",
        "\n",
        "def compute_bias_metrics_for_model(dataset,\n",
        "                                   subgroups,\n",
        "                                   model,\n",
        "                                   label_col,\n",
        "                                   include_asegs=False):\n",
        "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
        "    records = []\n",
        "    for subgroup in subgroups:\n",
        "        record = {\n",
        "            'subgroup': subgroup,\n",
        "            'subgroup_size': len(dataset[dataset[subgroup]>0.5])\n",
        "        }\n",
        "        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n",
        "        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n",
        "        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n",
        "        records.append(record)\n",
        "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttj2weh252Bp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "abe57cc2-8e63-4037-974b-acae50f74ce0"
      },
      "source": [
        "identity_columns = [\n",
        "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
        "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
        "MODEL_NAME = 'model1'\n",
        "test_df[MODEL_NAME]=hehe[0].flatten()\n",
        "TOXICITY_COLUMN = 'target'\n",
        "bias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, 'target')\n",
        "bias_metrics_df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bnsp_auc</th>\n",
              "      <th>bpsn_auc</th>\n",
              "      <th>subgroup</th>\n",
              "      <th>subgroup_auc</th>\n",
              "      <th>subgroup_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.963948</td>\n",
              "      <td>0.904455</td>\n",
              "      <td>black</td>\n",
              "      <td>0.886296</td>\n",
              "      <td>1357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.964249</td>\n",
              "      <td>0.916736</td>\n",
              "      <td>white</td>\n",
              "      <td>0.897247</td>\n",
              "      <td>2340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.957101</td>\n",
              "      <td>0.928201</td>\n",
              "      <td>homosexual_gay_or_lesbian</td>\n",
              "      <td>0.904812</td>\n",
              "      <td>1021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.958783</td>\n",
              "      <td>0.938699</td>\n",
              "      <td>muslim</td>\n",
              "      <td>0.918490</td>\n",
              "      <td>1929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.963351</td>\n",
              "      <td>0.955292</td>\n",
              "      <td>male</td>\n",
              "      <td>0.948432</td>\n",
              "      <td>3966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.956987</td>\n",
              "      <td>0.962144</td>\n",
              "      <td>jewish</td>\n",
              "      <td>0.951142</td>\n",
              "      <td>714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.960643</td>\n",
              "      <td>0.962750</td>\n",
              "      <td>female</td>\n",
              "      <td>0.952999</td>\n",
              "      <td>5100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.952749</td>\n",
              "      <td>0.971893</td>\n",
              "      <td>christian</td>\n",
              "      <td>0.959475</td>\n",
              "      <td>3511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.973574</td>\n",
              "      <td>0.950253</td>\n",
              "      <td>psychiatric_or_mental_illness</td>\n",
              "      <td>0.960511</td>\n",
              "      <td>393</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bnsp_auc  bpsn_auc  ... subgroup_auc  subgroup_size\n",
              "6  0.963948  0.904455  ...     0.886296           1357\n",
              "7  0.964249  0.916736  ...     0.897247           2340\n",
              "2  0.957101  0.928201  ...     0.904812           1021\n",
              "5  0.958783  0.938699  ...     0.918490           1929\n",
              "0  0.963351  0.955292  ...     0.948432           3966\n",
              "4  0.956987  0.962144  ...     0.951142            714\n",
              "1  0.960643  0.962750  ...     0.952999           5100\n",
              "3  0.952749  0.971893  ...     0.959475           3511\n",
              "8  0.973574  0.950253  ...     0.960511            393\n",
              "\n",
              "[9 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quYwdSxnZe4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fb57f98-756f-420c-e167-feac1dce58f9"
      },
      "source": [
        "get_final_metric(bias_metrics_df, calculate_overall_auc(test_df, MODEL_NAME))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.952892698891049"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qda1XUMBEqEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "bcf5ac43-b3cf-437b-cccd-3b579c9470d4"
      },
      "source": [
        "model3.save('ep1.h5')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU decay_steps: 33841.0\n",
            "INFO:tensorflow:TPU -> CPU warmup_steps: 1692.0\n",
            "INFO:tensorflow:TPU -> CPU min_lr: 0.0\n",
            "INFO:tensorflow:TPU -> CPU lr: 2.9999999242136255e-05\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU kernel_weight_decay: 0.009999999776482582\n",
            "INFO:tensorflow:TPU -> CPU bias_weight_decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW27I0YG8GBr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "dcdbd0b2-94ac-4fa4-d2e0-c63d0d993a77"
      },
      "source": [
        "ep2idx = np.arange(180032*9)\n",
        "np.random.shuffle(ep2idx)\n",
        "def run1p5():\n",
        "  token_input = (np.load('new7_train_input_220.npy')[train_idx])\n",
        "  with tf.keras.utils.custom_object_scope(get_custom_objects()):\n",
        "    K.set_value(model3.optimizer.lr, 1e-5)\n",
        "    mask_input = np.ones((180032,maxlen))\n",
        "    for i in range(5):\n",
        "      seg_input = np.zeros((180032,maxlen))\n",
        "      #seg_input[(token_input[ep2idx[(180032*i):(180032*(i+1))]!=0]=1\n",
        "      model3.fit([token_input[ep2idx[(180032*i):(180032*(i+1))]], seg_input, mask_input],[y[ep2idx[(180032*i):(180032*(i+1))]],\n",
        "                                                                                  y_aux[ep2idx[(180032*i):(180032*(i+1))]]],batch_size=bsz,epochs=nb_epochs)\n",
        "  return model3\n",
        "model3 = run1p5()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180032/180032 [==============================] - 1421s 8ms/sample - loss: 0.6643 - real_output_loss: 0.0776 - aux_output_loss: 0.0776\n",
            "180032/180032 [==============================] - 1424s 8ms/sample - loss: 0.6703 - real_output_loss: 0.0782 - aux_output_loss: 0.0782\n",
            "180032/180032 [==============================] - 1424s 8ms/sample - loss: 0.6613 - real_output_loss: 0.0772 - aux_output_loss: 0.0772\n",
            "180032/180032 [==============================] - 1428s 8ms/sample - loss: 0.6667 - real_output_loss: 0.0778 - aux_output_loss: 0.0778\n",
            "180032/180032 [==============================] - 1431s 8ms/sample - loss: 0.6637 - real_output_loss: 0.0775 - aux_output_loss: 0.0775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loDA47f68zNz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "a12a72d4-03af-45c7-c2fc-76c5416110dc"
      },
      "source": [
        "def run_pred1p5():\n",
        "  #token_input = (np.load('new7_train_input_220.npy')[train_idx])  \n",
        "  #token_input2 = token_input[-180032:]\n",
        "  token_input2 = np.load('token_input2.npy')\n",
        "  with tf.keras.utils.custom_object_scope(get_custom_objects()):\n",
        "    mask_input =  np.ones((180032,maxlen))\n",
        "    seg_input = np.zeros((180032,maxlen))\n",
        "    #seg_input[token_input2!=0]=1\n",
        "    hehe = model3.predict([token_input2, seg_input, mask_input],verbose=1,batch_size=bsz)\n",
        "  return hehe\n",
        "hehe = run_pred1p5()\n",
        "test_df[MODEL_NAME]=hehe[0].flatten()\n",
        "bias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, 'target')\n",
        "bias_metrics_df"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180032/180032 [==============================] - 354s 2ms/sample\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bnsp_auc</th>\n",
              "      <th>bpsn_auc</th>\n",
              "      <th>subgroup</th>\n",
              "      <th>subgroup_auc</th>\n",
              "      <th>subgroup_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.965467</td>\n",
              "      <td>0.907034</td>\n",
              "      <td>black</td>\n",
              "      <td>0.891643</td>\n",
              "      <td>1357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.963930</td>\n",
              "      <td>0.922880</td>\n",
              "      <td>white</td>\n",
              "      <td>0.901203</td>\n",
              "      <td>2340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.966191</td>\n",
              "      <td>0.913683</td>\n",
              "      <td>homosexual_gay_or_lesbian</td>\n",
              "      <td>0.906153</td>\n",
              "      <td>1021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.963740</td>\n",
              "      <td>0.933834</td>\n",
              "      <td>muslim</td>\n",
              "      <td>0.920936</td>\n",
              "      <td>1929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.960001</td>\n",
              "      <td>0.957616</td>\n",
              "      <td>jewish</td>\n",
              "      <td>0.947178</td>\n",
              "      <td>714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.964762</td>\n",
              "      <td>0.956409</td>\n",
              "      <td>male</td>\n",
              "      <td>0.950443</td>\n",
              "      <td>3966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.961387</td>\n",
              "      <td>0.963063</td>\n",
              "      <td>female</td>\n",
              "      <td>0.953070</td>\n",
              "      <td>5100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.977485</td>\n",
              "      <td>0.943386</td>\n",
              "      <td>psychiatric_or_mental_illness</td>\n",
              "      <td>0.959760</td>\n",
              "      <td>393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.957337</td>\n",
              "      <td>0.970830</td>\n",
              "      <td>christian</td>\n",
              "      <td>0.961549</td>\n",
              "      <td>3511</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bnsp_auc  bpsn_auc  ... subgroup_auc  subgroup_size\n",
              "6  0.965467  0.907034  ...     0.891643           1357\n",
              "7  0.963930  0.922880  ...     0.901203           2340\n",
              "2  0.966191  0.913683  ...     0.906153           1021\n",
              "5  0.963740  0.933834  ...     0.920936           1929\n",
              "4  0.960001  0.957616  ...     0.947178            714\n",
              "0  0.964762  0.956409  ...     0.950443           3966\n",
              "1  0.961387  0.963063  ...     0.953070           5100\n",
              "8  0.977485  0.943386  ...     0.959760            393\n",
              "3  0.957337  0.970830  ...     0.961549           3511\n",
              "\n",
              "[9 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LlFsd-q86bx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "137acd62-beb1-4047-bff9-bc906f01bab0"
      },
      "source": [
        "get_final_metric(bias_metrics_df, calculate_overall_auc(test_df, MODEL_NAME))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9536535785034861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qDnTvC4XqI0_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "36925db0-8931-4348-8b53-6417ef79f5a5"
      },
      "source": [
        "model3.save('ep1p5.h5')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU decay_steps: 33841.0\n",
            "INFO:tensorflow:TPU -> CPU warmup_steps: 1692.0\n",
            "INFO:tensorflow:TPU -> CPU min_lr: 0.0\n",
            "INFO:tensorflow:TPU -> CPU lr: 9.999999747378752e-06\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU kernel_weight_decay: 0.009999999776482582\n",
            "INFO:tensorflow:TPU -> CPU bias_weight_decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feUEdbDb_Inu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3c51f972-5aeb-4767-a273-8b2bfffd808c"
      },
      "source": [
        "def runep2():\n",
        "  token_input = (np.load('new7_train_input_220.npy')[train_idx])  \n",
        "  with tf.keras.utils.custom_object_scope(get_custom_objects()):\n",
        "    for i in range(5,9):\n",
        "      mask_input =  np.ones((180032,maxlen))\n",
        "      seg_input = np.zeros((180032,maxlen))\n",
        "      model3.fit([token_input[ep2idx[(180032*i):(180032*(i+1))]], seg_input, mask_input],[y[ep2idx[(180032*i):(180032*(i+1))]],\n",
        "                                                                                  y_aux[ep2idx[(180032*i):(180032*(i+1))]]],batch_size=bsz,epochs=nb_epochs)\n",
        "  return model3\n",
        "model3 = runep2()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180032/180032 [==============================] - 1423s 8ms/sample - loss: 0.6629 - real_output_loss: 0.0774 - aux_output_loss: 0.0774\n",
            "180032/180032 [==============================] - 1423s 8ms/sample - loss: 0.6648 - real_output_loss: 0.0776 - aux_output_loss: 0.0776\n",
            "180032/180032 [==============================] - 1422s 8ms/sample - loss: 0.6640 - real_output_loss: 0.0774 - aux_output_loss: 0.0774\n",
            "180032/180032 [==============================] - 1424s 8ms/sample - loss: 0.6654 - real_output_loss: 0.0776 - aux_output_loss: 0.0776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IONhZqZd_LhA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "4e254834-76fc-4cc8-fb6a-12ddab0d3adb"
      },
      "source": [
        "def run_pred2():\n",
        "  #token_input = (np.load('new7_train_input_220.npy')[train_idx])  \n",
        "  token_input2 = np.load('token_input2.npy')\n",
        "  with tf.keras.utils.custom_object_scope(get_custom_objects()):\n",
        "    mask_input =  np.ones((180032,maxlen))\n",
        "    seg_input = np.zeros((180032,maxlen))\n",
        "    hehe = model3.predict([token_input2, seg_input, mask_input],verbose=1,batch_size=bsz)\n",
        "  return hehe\n",
        "hehe = run_pred2()\n",
        "test_df[MODEL_NAME]=hehe[0].flatten()\n",
        "bias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, 'target')\n",
        "bias_metrics_df"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180032/180032 [==============================] - 354s 2ms/sample\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bnsp_auc</th>\n",
              "      <th>bpsn_auc</th>\n",
              "      <th>subgroup</th>\n",
              "      <th>subgroup_auc</th>\n",
              "      <th>subgroup_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.965467</td>\n",
              "      <td>0.907034</td>\n",
              "      <td>black</td>\n",
              "      <td>0.891643</td>\n",
              "      <td>1357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.963930</td>\n",
              "      <td>0.922880</td>\n",
              "      <td>white</td>\n",
              "      <td>0.901203</td>\n",
              "      <td>2340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.966191</td>\n",
              "      <td>0.913683</td>\n",
              "      <td>homosexual_gay_or_lesbian</td>\n",
              "      <td>0.906153</td>\n",
              "      <td>1021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.963740</td>\n",
              "      <td>0.933834</td>\n",
              "      <td>muslim</td>\n",
              "      <td>0.920936</td>\n",
              "      <td>1929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.960001</td>\n",
              "      <td>0.957616</td>\n",
              "      <td>jewish</td>\n",
              "      <td>0.947178</td>\n",
              "      <td>714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.964762</td>\n",
              "      <td>0.956409</td>\n",
              "      <td>male</td>\n",
              "      <td>0.950443</td>\n",
              "      <td>3966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.961387</td>\n",
              "      <td>0.963063</td>\n",
              "      <td>female</td>\n",
              "      <td>0.953070</td>\n",
              "      <td>5100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.977485</td>\n",
              "      <td>0.943386</td>\n",
              "      <td>psychiatric_or_mental_illness</td>\n",
              "      <td>0.959760</td>\n",
              "      <td>393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.957337</td>\n",
              "      <td>0.970830</td>\n",
              "      <td>christian</td>\n",
              "      <td>0.961549</td>\n",
              "      <td>3511</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bnsp_auc  bpsn_auc  ... subgroup_auc  subgroup_size\n",
              "6  0.965467  0.907034  ...     0.891643           1357\n",
              "7  0.963930  0.922880  ...     0.901203           2340\n",
              "2  0.966191  0.913683  ...     0.906153           1021\n",
              "5  0.963740  0.933834  ...     0.920936           1929\n",
              "4  0.960001  0.957616  ...     0.947178            714\n",
              "0  0.964762  0.956409  ...     0.950443           3966\n",
              "1  0.961387  0.963063  ...     0.953070           5100\n",
              "8  0.977485  0.943386  ...     0.959760            393\n",
              "3  0.957337  0.970830  ...     0.961549           3511\n",
              "\n",
              "[9 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhBRi62L_NWD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2abf3410-b291-48bf-d03e-bb2f441c12c8"
      },
      "source": [
        "get_final_metric(bias_metrics_df, calculate_overall_auc(test_df, MODEL_NAME))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9536535785034861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li4coOQKRdZo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "99f989b6-baae-4369-9857-6631325c40f3"
      },
      "source": [
        "!unzip predict_bertpre_220.zip.zip"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  predict_bertpre_220.zip.zip\n",
            "  inflating: bertpredict.npy         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUpM90fD_Tln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "657e8bb6-e802-4785-e086-ae22c2bad470"
      },
      "source": [
        "#valid test data\n",
        "#token_input2 = np.load('predict_gpt2raw260.npy')\n",
        "#token_input2 = np.load('predict_gpt2pre2_260.npy')\n",
        "#token_input2 = np.load('predict_gpt2raw260mask.npy')\n",
        "def testep2():\n",
        "  token_input2 = np.load('bertpredict.npy')\n",
        "  seg_input = np.zeros((token_input2.shape[0],maxlen))\n",
        "  mask_input = np.ones((token_input2.shape[0],maxlen))\n",
        "  print('valid data done')\n",
        "  print(token_input2.shape)\n",
        "  print(seg_input.shape)\n",
        "  print(mask_input.shape)\n",
        "  with tf.keras.utils.custom_object_scope(get_custom_objects()):\n",
        "    hehe = model3.predict([token_input2, seg_input, mask_input],verbose=1,batch_size=120)\n",
        "  return hehe\n",
        "hehe = testep2()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "valid data done\n",
            "(97320, 220)\n",
            "(97320, 220)\n",
            "(97320, 220)\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=infer (# of cores 8), [TensorSpec(shape=(15, 220), dtype=tf.float32, name='Input-Token_10'), TensorSpec(shape=(15, 220), dtype=tf.float32, name='Input-Segment_10'), TensorSpec(shape=(15, 220), dtype=tf.float32, name='Input-Masked_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for Input-Token\n",
            "INFO:tensorflow:Remapping placeholder for Input-Segment\n",
            "INFO:tensorflow:Remapping placeholder for Input-Masked\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 64.12428975105286 secs\n",
            "97320/97320 [==============================] - 299s 3ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZiYdCt7_ZK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('bert_pre_220_94929',hehe[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBYw-FQIXhhy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "fc651f77-915c-43d9-e684-74a20f76cd34"
      },
      "source": [
        "model3.save('9513xxep2bertlarge.h5')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU decay_steps: 33841.0\n",
            "INFO:tensorflow:TPU -> CPU warmup_steps: 1692.0\n",
            "INFO:tensorflow:TPU -> CPU min_lr: 0.0\n",
            "INFO:tensorflow:TPU -> CPU lr: 9.999999747378752e-06\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU kernel_weight_decay: 0.009999999776482582\n",
            "INFO:tensorflow:TPU -> CPU bias_weight_decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx_E2utwj59a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-JcGZ8x3lum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path_1 = '9513xxep2bertlarge.h5'\n",
        "file1 = drive.CreateFile()\n",
        "file1.SetContentFile(file_path_1)\n",
        "file1.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeQDczq76P1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}